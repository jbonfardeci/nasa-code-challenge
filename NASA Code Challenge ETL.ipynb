{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "XML_DATA_URL = 'https://afdata.s3.us-gov-west-1.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def read_files(path, ext):\n",
    "    file_list = []\n",
    "    for root, folders, docs in os.walk(path):\n",
    "        file_list.extend( [os.path.join(root, doc) for doc in docs if ext in doc] )\n",
    "\n",
    "    return file_listException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download XML list of data sources.\n",
    "xml_data_path = DATA_DIR+'/data_sources.xml'\n",
    "xml_data = download_url(XML_DATA_URL, xml_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download all zip data files from the XML source.\n",
    "with open(xml_data_path, 'r') as xml:\n",
    "    soup = BeautifulSoup(xml, 'xml')\n",
    "    \n",
    "    # XML structure: <Contents><Key>filename</Key><Size>bytes</Size></Contents>\n",
    "    contents_elements = soup.find_all('Contents')\n",
    "    \n",
    "    for contents in contents_elements:\n",
    "        key = contents.find('Key')\n",
    "        filename = str(key.text)\n",
    "        if not re.search(r'\\.zip$', filename):\n",
    "            continue\n",
    "        \n",
    "        save_path = str.format('{0}/{1}', DATA_DIR, filename)\n",
    "        url = str.format('{0}/{1}', XML_DATA_URL, filename)     \n",
    "        expected_size = int(str(contents.find('Size').text))\n",
    "        \n",
    "        # Only download if the file doesn't exist with the expected size in bytes.\n",
    "        if os.path.exists(save_path):\n",
    "            actual_size = os.path.getsize(save_path)\n",
    "            if expected_size == actual_size:\n",
    "                print(str.format('{0} at {1} bytes already exists.', filename, expected_size))\n",
    "                continue\n",
    "        \n",
    "        print(str.format('Downloading {0}...', url))\n",
    "        \n",
    "        download_url(url, save_path)\n",
    "        actual_size = os.path.getsize(save_path)\n",
    "        \n",
    "        if actual_size != expected_size:\n",
    "            print(str.format('WARNING: File size for {0} at {1} bytes does not match the expected size of {2} bytes.',\n",
    "                            filename, actual_size, expected_size))\n",
    "        else:  \n",
    "            print(str.format('Successfully downloaded {0} to {1}. Filesize: {2} bytes.'\n",
    "                             , url, save_path, actual_size))\n",
    "        \n",
    "    xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip all data files.\n",
    "for path in read_files(path=DATA_DIR, ext='.zip'):\n",
    "    extract_path = '/'.join(str(path).rsplit('/')[:-1]) + '/unzipped/'\n",
    "    with ZipFile(path, 'r') as zipfile:\n",
    "        zipfile.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned ./data/Scenario_Data/TLE/test.clean.txt\n"
     ]
    }
   ],
   "source": [
    "def julian_to_iso(julian):\n",
    "    yr = int(julian[:2])\n",
    "    yr = (2000+yr) if yr < 21 else (1900+yr)\n",
    "    day = math.floor(float(julian[2:]))\n",
    "    fraction = float('.'+julian.split('.')[1])\n",
    "    dec_hours = fraction*24\n",
    "    startdate = datetime(year=yr, month=1, day=1)\n",
    "    startdate += timedelta(days=day)\n",
    "    startdate += timedelta(hours=dec_hours)\n",
    "    return startdate.isoformat()\n",
    "    \n",
    "def get_intnl_designators(val):\n",
    "    \"\"\"\n",
    "    Extract LaunchYear, NthLaunch, CharLaunchObject from International Designator.\n",
    "        e.g. International Designator = '84123A' \n",
    "        where '84' is launch yr, \n",
    "        '123' is nth launch, \n",
    "        and 'A' is nth object resulting from this launch.\n",
    "    \"\"\"\n",
    "    if len(val) > 0:\n",
    "        launch_year = int(val[:2])\n",
    "        launch_year = 2000 + launch_year if (launch_year < 21) else (1900 + launch_year)\n",
    "        nth_launch = int(val[2:5])\n",
    "        char_launch_obj = re.sub(r'[^A-Z]', '', val)\n",
    "        return [str(launch_year), str(nth_launch), char_launch_obj]\n",
    "    \n",
    "    return ['', '', '']\n",
    " \n",
    "def trim(s):\n",
    "    return re.sub(r'(^\\s+|\\s+$)', '', s)\n",
    "    \n",
    "def clean_tle_line(line):\n",
    "    \n",
    "    nl = '\\n' if re.search(r'\\n', line) and re.search(r'^2\\s', line) else ''\n",
    "    line = trim(line)\n",
    "    \n",
    "    row = []\n",
    "    if re.search('^1\\s', line):  \n",
    "        line = re.sub(r'\\\\', '', line)\n",
    "        \n",
    "        # col 1 - SatId\n",
    "        satId = trim(line[2:8])\n",
    "        row.extend([satId, '|'])\n",
    "        \n",
    "        # col 5 - EpochYear, Convert Julian date to ISO: \n",
    "        julian_date = trim(line[17:32])\n",
    "        if julian_date:\n",
    "            julian_date = julian_to_iso(julian_date)\n",
    "         \n",
    "        row.extend([julian_date, '|'])\n",
    "        \n",
    "        row.extend([line, '|'])\n",
    "    else:\n",
    "        row.append(line)\n",
    "        \n",
    "    return ''.join(row) + nl\n",
    "\n",
    "def clean_tle_file(path):\n",
    "    path = path if type(path) != type([]) else path[0]\n",
    "    \"\"\"\n",
    "    Clean TLE file.\n",
    "    \"\"\"\n",
    "    filename = re.sub(r'\\.txt$', '.clean.txt', path)\n",
    "    with open(path, 'r') as file:\n",
    "        with open(filename, 'w', encoding='utf-8') as newfile:\n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    file.close()\n",
    "                    newfile.close()\n",
    "                    print('Cleaned', filename)\n",
    "                    break\n",
    "\n",
    "                cleaned_line = clean_tle_line(line)\n",
    "                newfile.write(cleaned_line)\n",
    "\n",
    "                \n",
    "def clean_tle_files(filelist, process_chunk, num_processes=0):\n",
    "    \"\"\"\n",
    "    Clean TLE data over N logical cores. Save as pipe delimitted datasets.\n",
    "    @param num_processes<int> - the number of logical CPU cores on a system.\n",
    "    \"\"\"\n",
    "\n",
    "    if num_processes == 0:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "            \n",
    "    list_len = len(filelist)\n",
    "    n = math.ceil(list_len/num_processes) if list_len > num_processes else list_len\n",
    "    chunks = [filelist[i:i + n] for i in range(0, list_len, n)]\n",
    "    procs = [] \n",
    "    for chunk in chunks:\n",
    "        p = Process(target=process_chunk, args=(chunk,))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "            \n",
    "#tle_files = read_files('./data/Scenario_Data/TLE/unzipped', '.txt')\n",
    "tle_files = ['./data/Scenario_Data/TLE/test.txt']\n",
    "clean_tle_files(filelist=tle_files, process_chunk=clean_tle_file, num_processes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatID</th>\n",
       "      <th>LaunchYear</th>\n",
       "      <th>NthLaunch</th>\n",
       "      <th>CharLaunchObject</th>\n",
       "      <th>EpochYear</th>\n",
       "      <th>BallisticCoef</th>\n",
       "      <th>SecDerivMeanMotion</th>\n",
       "      <th>DragTerm</th>\n",
       "      <th>EphemerisType</th>\n",
       "      <th>ElemNumCheckSum</th>\n",
       "      <th>SatNumID</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>RightAscension</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ArgPerigree</th>\n",
       "      <th>MeanAnomaly</th>\n",
       "      <th>MeanMotion</th>\n",
       "      <th>RevNumEpochCheckSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26619U</td>\n",
       "      <td>2000</td>\n",
       "      <td>75</td>\n",
       "      <td>A</td>\n",
       "      <td>2004-04-28T20:00:49.183776</td>\n",
       "      <td>-.00012193</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>-27028-2</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>26619</td>\n",
       "      <td>98.2038</td>\n",
       "      <td>186.7557</td>\n",
       "      <td>0001921</td>\n",
       "      <td>94.7873</td>\n",
       "      <td>265.3585</td>\n",
       "      <td>14.57084849</td>\n",
       "      <td>182472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18549U</td>\n",
       "      <td>1968</td>\n",
       "      <td>91</td>\n",
       "      <td>DE</td>\n",
       "      <td>2004-04-28T14:18:48.216960</td>\n",
       "      <td>.00001801</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>25919-2</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>18549</td>\n",
       "      <td>62.2415</td>\n",
       "      <td>180.1561</td>\n",
       "      <td>0704892</td>\n",
       "      <td>265.6761</td>\n",
       "      <td>86.2771</td>\n",
       "      <td>12.85268417</td>\n",
       "      <td>585614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18727U</td>\n",
       "      <td>1987</td>\n",
       "      <td>20</td>\n",
       "      <td>E</td>\n",
       "      <td>2004-04-28T15:59:40.727904</td>\n",
       "      <td>-.00000002</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>4084</td>\n",
       "      <td>18727</td>\n",
       "      <td>73.3600</td>\n",
       "      <td>345.6887</td>\n",
       "      <td>0088152</td>\n",
       "      <td>270.3999</td>\n",
       "      <td>88.6911</td>\n",
       "      <td>12.64216608</td>\n",
       "      <td>754869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18792U</td>\n",
       "      <td>1988</td>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>2004-04-28T19:38:29.895648</td>\n",
       "      <td>.00000029</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>18792</td>\n",
       "      <td>82.6017</td>\n",
       "      <td>352.4844</td>\n",
       "      <td>0014698</td>\n",
       "      <td>138.3284</td>\n",
       "      <td>221.8930</td>\n",
       "      <td>12.65511631</td>\n",
       "      <td>752224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19027U</td>\n",
       "      <td>1981</td>\n",
       "      <td>53</td>\n",
       "      <td>MK</td>\n",
       "      <td>2004-04-28T19:45:13.686048</td>\n",
       "      <td>.00001280</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10755-2</td>\n",
       "      <td>0</td>\n",
       "      <td>7395</td>\n",
       "      <td>19027</td>\n",
       "      <td>83.0239</td>\n",
       "      <td>250.9465</td>\n",
       "      <td>0084934</td>\n",
       "      <td>184.3222</td>\n",
       "      <td>175.7249</td>\n",
       "      <td>13.85640082</td>\n",
       "      <td>953590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SatID LaunchYear NthLaunch CharLaunchObject                   EpochYear  \\\n",
       "0  26619U       2000        75                A  2004-04-28T20:00:49.183776   \n",
       "1  18549U       1968        91               DE  2004-04-28T14:18:48.216960   \n",
       "2  18727U       1987        20                E  2004-04-28T15:59:40.727904   \n",
       "3  18792U       1988         2                E  2004-04-28T19:38:29.895648   \n",
       "4  19027U       1981        53               MK  2004-04-28T19:45:13.686048   \n",
       "\n",
       "  BallisticCoef SecDerivMeanMotion  DragTerm EphemerisType ElemNumCheckSum  \\\n",
       "0    -.00012193            00000-0  -27028-2             0             720   \n",
       "1     .00001801            00000-0   25919-2             0             283   \n",
       "2    -.00000002            00000-0   10000-3             0            4084   \n",
       "3     .00000029            00000-0   10000-3             0            6838   \n",
       "4     .00001280            00000-0   10755-2             0            7395   \n",
       "\n",
       "  SatNumID Inclination RightAscension Eccentricity ArgPerigree MeanAnomaly  \\\n",
       "0    26619     98.2038       186.7557      0001921     94.7873    265.3585   \n",
       "1    18549     62.2415       180.1561      0704892    265.6761     86.2771   \n",
       "2    18727     73.3600       345.6887      0088152    270.3999     88.6911   \n",
       "3    18792     82.6017       352.4844      0014698    138.3284    221.8930   \n",
       "4    19027     83.0239       250.9465      0084934    184.3222    175.7249   \n",
       "\n",
       "    MeanMotion RevNumEpochCheckSum  \n",
       "0  14.57084849              182472  \n",
       "1  12.85268417              585614  \n",
       "2  12.64216608              754869  \n",
       "3  12.65511631              752224  \n",
       "4  13.85640082              953590  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tle_dtypes = {\n",
    "    'SatID': 'object'\n",
    "    , 'LaunchYear': np.int\n",
    "    , 'NthLaunch': np.int\n",
    "    , 'CharLaunchObject': 'object'\n",
    "    , 'EpochYear': 'object'\n",
    "    , 'BallisticCoef': 'object'\n",
    "    , 'SecDerivMeanMotion': 'object'\n",
    "    , 'DragTerm': 'object'\n",
    "    , 'EphemerisType': np.int\n",
    "    , 'ElemNumCheckSum': np.int\n",
    "    , 'SatNumID': 'object'\n",
    "    , 'Inclination': np.float\n",
    "    , 'RightAscension': np.float\n",
    "    , 'Eccentricity': np.float\n",
    "    , 'ArgPerigree': np.float\n",
    "    , 'MeanAnomaly': np.float\n",
    "    , 'MeanMotion': np.float\n",
    "    , 'RevNumEpochCheckSum': np.float\n",
    "}\n",
    "\n",
    "tle_columns = [col for col in tle_dtypes]\n",
    "\n",
    "tle_data = dd.read_csv('./data/Scenario_Data/TLE/unzipped/*.clean.txt'\n",
    "                       , names=tle_columns\n",
    "                       , dtype=tle_dtypes\n",
    "                       , sep='|'\n",
    "                       , encoding='utf-8'\n",
    "                      )\n",
    "\n",
    "tle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44318\n"
     ]
    }
   ],
   "source": [
    "unique_ids = tle_data['SatID'].unique().count().compute()\n",
    "print(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 TLE data\n",
    "tle_data = dd.read_csv('./data/Scenario_Data/TLE/unzipped/*.clean.txt'\n",
    "                       , names=tle_columns\n",
    "                       , dtype=tle_dtypes\n",
    "                       , sep='|'\n",
    "                       , encoding='utf-8'\n",
    "                      )\n",
    "\n",
    "tle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AIS data\n",
    "\n",
    "# Relocate CSV files to main AIS directory.\n",
    "ais_files = read_files('./data/Scenario_Data/AIS/unzipped/AIS_ASCII_by_UTM_Month', '.csv')\n",
    "for path in ais_files:\n",
    "    filename = os.path.basename(path)\n",
    "    print(filename)\n",
    "    shutil.move(path, './data/Scenario_Data/AIS/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>BaseDateTime</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "      <th>VesselName</th>\n",
       "      <th>IMO</th>\n",
       "      <th>CallSign</th>\n",
       "      <th>VesselType</th>\n",
       "      <th>Status</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Draft</th>\n",
       "      <th>Cargo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235091871.0</td>\n",
       "      <td>2015-01-01T00:08:26</td>\n",
       "      <td>52.78763</td>\n",
       "      <td>-175.62761</td>\n",
       "      <td>10.3</td>\n",
       "      <td>74.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>EVA BULKER</td>\n",
       "      <td>IMO9544164</td>\n",
       "      <td>2FJU4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>185.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T05:36:17</td>\n",
       "      <td>52.87994</td>\n",
       "      <td>-176.21738</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-148.8</td>\n",
       "      <td>263.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:28:57</td>\n",
       "      <td>52.83234</td>\n",
       "      <td>-176.46662</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.8</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:32:27</td>\n",
       "      <td>52.82851</td>\n",
       "      <td>-176.48291</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.6</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:36:07</td>\n",
       "      <td>52.82446</td>\n",
       "      <td>-176.50022</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MMSI         BaseDateTime       LAT        LON   SOG    COG  \\\n",
       "0  235091871.0  2015-01-01T00:08:26  52.78763 -175.62761  10.3   74.5   \n",
       "1  247119100.0  2015-01-01T05:36:17  52.87994 -176.21738  10.7 -148.8   \n",
       "2  247119100.0  2015-01-01T06:28:57  52.83234 -176.46662  11.0 -160.8   \n",
       "3  247119100.0  2015-01-01T06:32:27  52.82851 -176.48291  11.0 -160.6   \n",
       "4  247119100.0  2015-01-01T06:36:07  52.82446 -176.50022  11.0 -160.0   \n",
       "\n",
       "   Heading  VesselName         IMO CallSign  VesselType  \\\n",
       "0     86.0  EVA BULKER  IMO9544164    2FJU4        70.0   \n",
       "1    263.0        POLE  IMO9128245     IBTE        70.0   \n",
       "2    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "3    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "4    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "\n",
       "                   Status  Length  Width  Draft  Cargo  \n",
       "0  under way using engine   185.0   31.0    6.6   70.0  \n",
       "1  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "2  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "3  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "4  under way using engine   224.0   32.0  -12.8   70.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine AIS CSV files.\n",
    "ais_data = dd.read_csv('./data/Scenario_Data/AIS/*.csv', assume_missing=True)\n",
    "ais_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

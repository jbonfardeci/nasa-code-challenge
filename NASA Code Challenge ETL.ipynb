{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "XML_DATA_URL = 'https://afdata.s3.us-gov-west-1.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def read_files(path, ext):\n",
    "    file_list = []\n",
    "    for root, folders, docs in os.walk(path):\n",
    "        file_list.extend( [os.path.join(root, doc) for doc in docs if ext in doc] )\n",
    "\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download XML list of data sources.\n",
    "xml_data_path = DATA_DIR+'/data_sources.xml'\n",
    "xml_data = download_url(XML_DATA_URL, xml_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download all zip data files from the XML source.\n",
    "with open(xml_data_path, 'r') as xml:\n",
    "    soup = BeautifulSoup(xml, 'xml')\n",
    "    \n",
    "    # XML structure: <Contents><Key>filename</Key><Size>bytes</Size></Contents>\n",
    "    contents_elements = soup.find_all('Contents')\n",
    "    \n",
    "    for contents in contents_elements:\n",
    "        key = contents.find('Key')\n",
    "        filename = str(key.text)\n",
    "        if not re.search(r'\\.zip$', filename):\n",
    "            continue\n",
    "        \n",
    "        save_path = str.format('{0}/{1}', DATA_DIR, filename)\n",
    "        url = str.format('{0}/{1}', XML_DATA_URL, filename)     \n",
    "        expected_size = int(str(contents.find('Size').text))\n",
    "        \n",
    "        # Only download if the file doesn't exist with the expected size in bytes.\n",
    "        if os.path.exists(save_path):\n",
    "            actual_size = os.path.getsize(save_path)\n",
    "            if expected_size == actual_size:\n",
    "                print(str.format('{0} at {1} bytes already exists.', filename, expected_size))\n",
    "                continue\n",
    "        \n",
    "        print(str.format('Downloading {0}...', url))\n",
    "        \n",
    "        download_url(url, save_path)\n",
    "        actual_size = os.path.getsize(save_path)\n",
    "        \n",
    "        if actual_size != expected_size:\n",
    "            print(str.format('WARNING: File size for {0} at {1} bytes does not match the expected size of {2} bytes.',\n",
    "                            filename, actual_size, expected_size))\n",
    "        else:  \n",
    "            print(str.format('Successfully downloaded {0} to {1}. Filesize: {2} bytes.'\n",
    "                             , url, save_path, actual_size))\n",
    "        \n",
    "    xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip all data files.\n",
    "for path in read_files(path=DATA_DIR, ext='.zip'):\n",
    "    extract_path = '/'.join(str(path).rsplit('/')[:-1]) + '/unzipped/'\n",
    "    with ZipFile(path, 'r') as zipfile:\n",
    "        zipfile.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned ./data/Scenario_Data/TLE/test.clean.txt\n"
     ]
    }
   ],
   "source": [
    "def julian_to_iso(julian):\n",
    "    yr = int(julian[:2])\n",
    "    yr = (2000+yr) if yr < 21 else (1900+yr)\n",
    "    day = math.floor(float(julian[2:]))\n",
    "    fraction = float('.'+julian.split('.')[1])\n",
    "    dec_hours = fraction*24\n",
    "    hours = math.floor(dec_hours)\n",
    "    dec_minutes = (dec_hours-hours)*60\n",
    "    minutes = math.floor(dec_minutes)\n",
    "    seconds = (dec_minutes-minutes)*60\n",
    "    startdate = datetime(year=yr, month=1, day=1)\n",
    "    startdate += timedelta(days=day)\n",
    "    startdate += timedelta(hours=dec_hours)\n",
    "    return startdate.isoformat()\n",
    "    \n",
    "def clean_intnl_designator(line):\n",
    "    \"\"\"\n",
    "    Extract LaunchYear, NthLaunch, CharLaunchObject from International Designator.\n",
    "        e.g. International Designator = '84123A' \n",
    "        where '84' is launch yr, \n",
    "        '123' is nth launch, \n",
    "        and 'A' is nth object resulting from this launch.\n",
    "    \"\"\"\n",
    "    intnl_desig = re.findall(r'(?<=\\|)\\d{5}[A-Z]{1,2}(?=\\|)', line)\n",
    "    if len(intnl_desig) > 0:\n",
    "        val = intnl_desig[0]\n",
    "        launch_year = int(val[:2])\n",
    "        launch_year = 2000 + launch_year if (launch_year < 21) else (1900 + launch_year)\n",
    "        nth_launch = int(val[2:5])\n",
    "        char_launch_obj = re.sub(r'[^A-Z]', '', val)\n",
    "        return line.replace(val, str.format(\"{0}|{1}|{2}\", launch_year, nth_launch, char_launch_obj))\n",
    "    \n",
    "    return line\n",
    " \n",
    "def clean_mean_motion(line):\n",
    "    \"\"\"\n",
    "    Sometimes Mean Motion and Revolution number are crammed together. Separate them.\n",
    "    \"\"\"\n",
    "    rx = r'(?<=\\|)\\d{1,2}\\.\\d{13}'\n",
    "    if re.search(rx, line):\n",
    "        last_num = re.findall(rx, line)[0]\n",
    "        mean_motion = last_num[:-5]\n",
    "        rev_num = last_num[-5:]\n",
    "        return line.replace(last_num, mean_motion+'|'+rev_num)\n",
    "    \n",
    "    return line\n",
    "        \n",
    "def clean_tle_line(line):\n",
    "    newline = ''\n",
    "    line2 = False\n",
    "    if re.search(r'^2', line):\n",
    "        newline = '\\r\\n'\n",
    "        line2 = True\n",
    "\n",
    "    line = re.sub(r'^(1|2)\\s+', '', line)\n",
    "    line = re.sub(r'(^\\s+|\\s+$)', '', line)\n",
    "    line = re.sub(r'\\\\', '|', line)\n",
    "    line = re.sub(r'\\s+', '|', line) \n",
    "\n",
    "    # Separate Mean Motion and Revolution Number.\n",
    "    if line2:\n",
    "        line = clean_mean_motion(line)\n",
    "\n",
    "    # Get International Designator parts\n",
    "    line = clean_intnl_designator(line)\n",
    "    \n",
    "    # Convert Julian date to ISO\n",
    "    if not line2:\n",
    "        julian_date = line.split('|')[4]\n",
    "        iso = julian_to_iso(julian_date)\n",
    "        line = line.replace(julian_date, iso)\n",
    "    \n",
    "    return line + newline\n",
    "\n",
    "# Clean TLE data. Save as pipe delimitted datasets.\n",
    "tle_files = read_files('./data/Scenario_Data/TLE/unzipped', '.txt')\n",
    "# tle_files = ['./data/Scenario_Data/TLE/test.txt']\n",
    "\n",
    "for path in tle_files:\n",
    "    filename = re.sub(r'\\.txt$', '.clean.txt', path)\n",
    "    with open(path, 'r') as file:\n",
    "        with open(filename, 'w', encoding='utf-8') as newfile:\n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    file.close()\n",
    "                    newfile.close()\n",
    "                    print('Cleaned', filename)\n",
    "                    break\n",
    "\n",
    "                cleaned_line = clean_tle_line(line)\n",
    "                newfile.write(cleaned_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatID</th>\n",
       "      <th>IntnlDesignator</th>\n",
       "      <th>EpochYear</th>\n",
       "      <th>BallisticCoef</th>\n",
       "      <th>SecDerivMeanMotion</th>\n",
       "      <th>DragTerm</th>\n",
       "      <th>EphemerisType</th>\n",
       "      <th>ElemNumCheckSum</th>\n",
       "      <th>SatNumID</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>RightAscension</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ArgPerigree</th>\n",
       "      <th>MeanAnomaly</th>\n",
       "      <th>MeanMotion</th>\n",
       "      <th>RevNumEpochCheckSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26619U</td>\n",
       "      <td>00075A</td>\n",
       "      <td>4118.833903</td>\n",
       "      <td>-.00012193</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>-27028-2</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>26619</td>\n",
       "      <td>98.2038</td>\n",
       "      <td>186.7557</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>94.7873</td>\n",
       "      <td>265.3585</td>\n",
       "      <td>14.570848</td>\n",
       "      <td>182472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18549U</td>\n",
       "      <td>68091DE</td>\n",
       "      <td>4118.596391</td>\n",
       "      <td>.00001801</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>25919-2</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>18549</td>\n",
       "      <td>62.2415</td>\n",
       "      <td>180.1561</td>\n",
       "      <td>704892.0</td>\n",
       "      <td>265.6761</td>\n",
       "      <td>86.2771</td>\n",
       "      <td>12.852684</td>\n",
       "      <td>585614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18727U</td>\n",
       "      <td>87020E</td>\n",
       "      <td>4118.666444</td>\n",
       "      <td>-.00000002</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>4084</td>\n",
       "      <td>18727</td>\n",
       "      <td>73.3600</td>\n",
       "      <td>345.6887</td>\n",
       "      <td>88152.0</td>\n",
       "      <td>270.3999</td>\n",
       "      <td>88.6911</td>\n",
       "      <td>12.642166</td>\n",
       "      <td>754869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18792U</td>\n",
       "      <td>88002E</td>\n",
       "      <td>4118.818402</td>\n",
       "      <td>.00000029</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>18792</td>\n",
       "      <td>82.6017</td>\n",
       "      <td>352.4844</td>\n",
       "      <td>14698.0</td>\n",
       "      <td>138.3284</td>\n",
       "      <td>221.8930</td>\n",
       "      <td>12.655116</td>\n",
       "      <td>752224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19027U</td>\n",
       "      <td>81053MK</td>\n",
       "      <td>4118.823075</td>\n",
       "      <td>.00001280</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10755-2</td>\n",
       "      <td>0</td>\n",
       "      <td>7395</td>\n",
       "      <td>19027</td>\n",
       "      <td>83.0239</td>\n",
       "      <td>250.9465</td>\n",
       "      <td>84934.0</td>\n",
       "      <td>184.3222</td>\n",
       "      <td>175.7249</td>\n",
       "      <td>13.856401</td>\n",
       "      <td>953590.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SatID IntnlDesignator    EpochYear BallisticCoef SecDerivMeanMotion  \\\n",
       "0  26619U          00075A  4118.833903    -.00012193            00000-0   \n",
       "1  18549U         68091DE  4118.596391     .00001801            00000-0   \n",
       "2  18727U          87020E  4118.666444    -.00000002            00000-0   \n",
       "3  18792U          88002E  4118.818402     .00000029            00000-0   \n",
       "4  19027U         81053MK  4118.823075     .00001280            00000-0   \n",
       "\n",
       "   DragTerm  EphemerisType  ElemNumCheckSum SatNumID  Inclination  \\\n",
       "0  -27028-2              0              720    26619      98.2038   \n",
       "1   25919-2              0              283    18549      62.2415   \n",
       "2   10000-3              0             4084    18727      73.3600   \n",
       "3   10000-3              0             6838    18792      82.6017   \n",
       "4   10755-2              0             7395    19027      83.0239   \n",
       "\n",
       "   RightAscension  Eccentricity  ArgPerigree  MeanAnomaly  MeanMotion  \\\n",
       "0        186.7557        1921.0      94.7873     265.3585   14.570848   \n",
       "1        180.1561      704892.0     265.6761      86.2771   12.852684   \n",
       "2        345.6887       88152.0     270.3999      88.6911   12.642166   \n",
       "3        352.4844       14698.0     138.3284     221.8930   12.655116   \n",
       "4        250.9465       84934.0     184.3222     175.7249   13.856401   \n",
       "\n",
       "   RevNumEpochCheckSum  \n",
       "0             182472.0  \n",
       "1             585614.0  \n",
       "2             754869.0  \n",
       "3             752224.0  \n",
       "4             953590.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tle_dtypes = {\n",
    "    'SatID': 'object'\n",
    "    , 'LaunchYear': np.int\n",
    "    , 'NthLaunch': np.int\n",
    "    , 'CharLaunchObject': 'object'\n",
    "    , 'EpochYear': np.float64\n",
    "    , 'BallisticCoef': 'object'\n",
    "    , 'SecDerivMeanMotion': 'object'\n",
    "    , 'DragTerm': 'object'\n",
    "    , 'EphemerisType': np.int\n",
    "    , 'ElemNumCheckSum': np.int\n",
    "    , 'SatNumID': 'object'\n",
    "    , 'Inclination': np.float\n",
    "    , 'RightAscension': np.float\n",
    "    , 'Eccentricity': np.float\n",
    "    , 'ArgPerigree': np.float\n",
    "    , 'MeanAnomaly': np.float\n",
    "    , 'MeanMotion': np.float\n",
    "    , 'RevNumEpochCheckSum': np.float\n",
    "}\n",
    "\n",
    "tle_columns = [col for col in tle_dtypes]\n",
    "\n",
    "tle_data = dd.read_csv('./data/Scenario_Data/TLE/unzipped/*.clean.txt'\n",
    "                       , names=tle_columns\n",
    "                       , dtype=tle_dtypes\n",
    "                       , sep='|'\n",
    "                       , encoding='utf-8'\n",
    "                      )\n",
    "\n",
    "tle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 TLE data\n",
    "tle_data = dd.read_csv('./data/Scenario_Data/TLE/unzipped/*.clean.txt'\n",
    "                       , names=tle_columns\n",
    "                       , dtype=tle_dtypes\n",
    "                       , sep='|'\n",
    "                       , encoding='utf-8'\n",
    "                      )\n",
    "\n",
    "tle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AIS data\n",
    "\n",
    "# Relocate CSV files to main AIS directory.\n",
    "ais_files = read_files('./data/Scenario_Data/AIS/unzipped/AIS_ASCII_by_UTM_Month', '.csv')\n",
    "for path in ais_files:\n",
    "    filename = os.path.basename(path)\n",
    "    print(filename)\n",
    "    shutil.move(path, './data/Scenario_Data/AIS/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>BaseDateTime</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>SOG</th>\n",
       "      <th>COG</th>\n",
       "      <th>Heading</th>\n",
       "      <th>VesselName</th>\n",
       "      <th>IMO</th>\n",
       "      <th>CallSign</th>\n",
       "      <th>VesselType</th>\n",
       "      <th>Status</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Draft</th>\n",
       "      <th>Cargo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235091871.0</td>\n",
       "      <td>2015-01-01T00:08:26</td>\n",
       "      <td>52.78763</td>\n",
       "      <td>-175.62761</td>\n",
       "      <td>10.3</td>\n",
       "      <td>74.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>EVA BULKER</td>\n",
       "      <td>IMO9544164</td>\n",
       "      <td>2FJU4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>185.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T05:36:17</td>\n",
       "      <td>52.87994</td>\n",
       "      <td>-176.21738</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-148.8</td>\n",
       "      <td>263.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:28:57</td>\n",
       "      <td>52.83234</td>\n",
       "      <td>-176.46662</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.8</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:32:27</td>\n",
       "      <td>52.82851</td>\n",
       "      <td>-176.48291</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.6</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247119100.0</td>\n",
       "      <td>2015-01-01T06:36:07</td>\n",
       "      <td>52.82446</td>\n",
       "      <td>-176.50022</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>POLE</td>\n",
       "      <td>IMO9128245</td>\n",
       "      <td>IBTE</td>\n",
       "      <td>70.0</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>224.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MMSI         BaseDateTime       LAT        LON   SOG    COG  \\\n",
       "0  235091871.0  2015-01-01T00:08:26  52.78763 -175.62761  10.3   74.5   \n",
       "1  247119100.0  2015-01-01T05:36:17  52.87994 -176.21738  10.7 -148.8   \n",
       "2  247119100.0  2015-01-01T06:28:57  52.83234 -176.46662  11.0 -160.8   \n",
       "3  247119100.0  2015-01-01T06:32:27  52.82851 -176.48291  11.0 -160.6   \n",
       "4  247119100.0  2015-01-01T06:36:07  52.82446 -176.50022  11.0 -160.0   \n",
       "\n",
       "   Heading  VesselName         IMO CallSign  VesselType  \\\n",
       "0     86.0  EVA BULKER  IMO9544164    2FJU4        70.0   \n",
       "1    263.0        POLE  IMO9128245     IBTE        70.0   \n",
       "2    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "3    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "4    254.0        POLE  IMO9128245     IBTE        70.0   \n",
       "\n",
       "                   Status  Length  Width  Draft  Cargo  \n",
       "0  under way using engine   185.0   31.0    6.6   70.0  \n",
       "1  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "2  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "3  under way using engine   224.0   32.0  -12.8   70.0  \n",
       "4  under way using engine   224.0   32.0  -12.8   70.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine AIS CSV files.\n",
    "ais_data = dd.read_csv('./data/Scenario_Data/AIS/*.csv', assume_missing=True)\n",
    "ais_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

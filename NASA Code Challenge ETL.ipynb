{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "XML_DATA_URL = 'https://afdata.s3.us-gov-west-1.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download XML list of data sources.\n",
    "xml_data_path = DATA_DIR+'/data_sources.xml'\n",
    "xml_data = download_url(XML_DATA_URL, xml_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario_Data/AIS/AIS_2015_01_Zone01.zip at 699204 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2015_01_Zone02.zip at 4800320 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2015_01_Zone03.zip at 50471539 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2016_01_Zone01.zip at 434183 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2016_01_Zone02.zip at 3169488 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2016_01_Zone03.zip at 55155734 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2017_01_Zone01.zip at 176297 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2017_01_Zone02.zip at 3566591 bytes already exists.\n",
      "Scenario_Data/AIS/AIS_2017_01_Zone03.zip at 52487368 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2009_01.zip at 520366084 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2010_01.zip at 503698861 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2011_01.gdb.zip at 425399907 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2012_01.gdb.zip at 603860220 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2013_01.gdb.zip at 782550331 bytes already exists.\n",
      "Scenario_Data/AIS/Zone10_2014_01.zip at 795921228 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_1of8.txt.zip at 98535452 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_2of8.txt.zip at 138679372 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_3of8.txt.zip at 136395889 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_4of8.txt.zip at 53923139 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_5of8.txt.zip at 41957867 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_6of8.txt.zip at 336212760 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_7of8.txt.zip at 1155271564 bytes already exists.\n",
      "Scenario_Data/TLE/tle2004_8of8.txt.zip at 77636269 bytes already exists.\n",
      "Scenario_Data/TLE/tle2005.txt.zip at 739773461 bytes already exists.\n",
      "Scenario_Data/TLE/tle2006.txt.zip at 225071007 bytes already exists.\n",
      "Scenario_Data/TLE/tle2007.txt.zip at 254524153 bytes already exists.\n",
      "Scenario_Data/TLE/tle2008.txt.zip at 255636100 bytes already exists.\n",
      "Scenario_Data/TLE/tle2009.txt.zip at 315313396 bytes already exists.\n",
      "Scenario_Data/TLE/tle2010.txt.zip at 297940878 bytes already exists.\n",
      "Scenario_Data/TLE/tle2011.txt.zip at 312017918 bytes already exists.\n",
      "Scenario_Data/TLE/tle2012.txt.zip at 294914984 bytes already exists.\n",
      "Scenario_Data/TLE/tle2013.txt.zip at 173809323 bytes already exists.\n",
      "Scenario_Data/TLE/tle2014.txt.zip at 186454135 bytes already exists.\n",
      "Scenario_Data/TLE/tle2015.txt.zip at 257481302 bytes already exists.\n",
      "Scenario_Data/TLE/tle2016.txt.zip at 367269752 bytes already exists.\n",
      "Scenario_Data/TLE/tle2017.txt.zip at 415956002 bytes already exists.\n",
      "Scenario_Data/TLE/tle2018.txt.zip at 481787586 bytes already exists.\n"
     ]
    }
   ],
   "source": [
    "# Download all zip data files from the XML source.\n",
    "with open(xml_data_path, 'r') as xml:\n",
    "    soup = BeautifulSoup(xml, 'xml')\n",
    "    \n",
    "    # XML structure: <Contents><Key>filename</Key><Size>bytes</Size></Contents>\n",
    "    contents_elements = soup.find_all('Contents')\n",
    "    \n",
    "    for contents in contents_elements:\n",
    "        key = contents.find('Key')\n",
    "        filename = str(key.text)\n",
    "        if not re.search(r'\\.zip$', filename):\n",
    "            continue\n",
    "        \n",
    "        save_path = str.format('{0}/{1}', DATA_DIR, filename)\n",
    "        url = str.format('{0}/{1}', XML_DATA_URL, filename)     \n",
    "        expected_size = int(str(contents.find('Size').text))\n",
    "        \n",
    "        # Only download if the file doesn't exist with the expected size in bytes.\n",
    "        if os.path.exists(save_path):\n",
    "            actual_size = os.path.getsize(save_path)\n",
    "            if expected_size == actual_size:\n",
    "                print(str.format('{0} at {1} bytes already exists.', filename, expected_size))\n",
    "                continue\n",
    "        \n",
    "        print(str.format('Downloading {0}...', url))\n",
    "        \n",
    "        download_url(url, save_path)\n",
    "        actual_size = os.path.getsize(save_path)\n",
    "        \n",
    "        if actual_size != expected_size:\n",
    "            print(str.format('WARNING: File size for {0} at {1} bytes does not match the expected size of {2} bytes.',\n",
    "                            filename, actual_size, expected_size))\n",
    "        else:  \n",
    "            print(str.format('Successfully downloaded {0} to {1}. Filesize: {2} bytes.'\n",
    "                             , url, save_path, actual_size))\n",
    "        \n",
    "    xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip all data files.\n",
    "def read_files(path, ext):\n",
    "    file_list = []\n",
    "    for root, folders, docs in os.walk(path):\n",
    "        file_list.extend( [os.path.join(root, doc) for doc in docs if ext in doc] )\n",
    "\n",
    "    return file_list\n",
    "\n",
    "for path in read_files(path=DATA_DIR, ext='.zip'):\n",
    "    extract_path = '/'.join(str(path).rsplit('/')[:-1]) + '/unzipped/'\n",
    "    with ZipFile(path, 'r') as zipfile:\n",
    "        zipfile.extractall(extract_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "XML_DATA_URL = 'https://afdata.s3.us-gov-west-1.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def read_files(path, ext):\n",
    "    file_list = []\n",
    "    for root, folders, docs in os.walk(path):\n",
    "        file_list.extend( [os.path.join(root, doc) for doc in docs if ext in doc] )\n",
    "\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download XML list of data sources.\n",
    "xml_data_path = DATA_DIR+'/data_sources.xml'\n",
    "xml_data = download_url(XML_DATA_URL, xml_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download all zip data files from the XML source.\n",
    "with open(xml_data_path, 'r') as xml:\n",
    "    soup = BeautifulSoup(xml, 'xml')\n",
    "    \n",
    "    # XML structure: <Contents><Key>filename</Key><Size>bytes</Size></Contents>\n",
    "    contents_elements = soup.find_all('Contents')\n",
    "    \n",
    "    for contents in contents_elements:\n",
    "        key = contents.find('Key')\n",
    "        filename = str(key.text)\n",
    "        if not re.search(r'\\.zip$', filename):\n",
    "            continue\n",
    "        \n",
    "        save_path = str.format('{0}/{1}', DATA_DIR, filename)\n",
    "        url = str.format('{0}/{1}', XML_DATA_URL, filename)     \n",
    "        expected_size = int(str(contents.find('Size').text))\n",
    "        \n",
    "        # Only download if the file doesn't exist with the expected size in bytes.\n",
    "        if os.path.exists(save_path):\n",
    "            actual_size = os.path.getsize(save_path)\n",
    "            if expected_size == actual_size:\n",
    "                print(str.format('{0} at {1} bytes already exists.', filename, expected_size))\n",
    "                continue\n",
    "        \n",
    "        print(str.format('Downloading {0}...', url))\n",
    "        \n",
    "        download_url(url, save_path)\n",
    "        actual_size = os.path.getsize(save_path)\n",
    "        \n",
    "        if actual_size != expected_size:\n",
    "            print(str.format('WARNING: File size for {0} at {1} bytes does not match the expected size of {2} bytes.',\n",
    "                            filename, actual_size, expected_size))\n",
    "        else:  \n",
    "            print(str.format('Successfully downloaded {0} to {1}. Filesize: {2} bytes.'\n",
    "                             , url, save_path, actual_size))\n",
    "        \n",
    "    xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip all data files.\n",
    "for path in read_files(path=DATA_DIR, ext='.zip'):\n",
    "    extract_path = '/'.join(str(path).rsplit('/')[:-1]) + '/unzipped/'\n",
    "    with ZipFile(path, 'r') as zipfile:\n",
    "        zipfile.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Scenario_Data/TLE/unzipped/tle2004_1of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_2of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_3of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_4of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_5of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_6of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_7of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2004_8of8.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2005.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2006.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2007.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2008.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2009.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2010.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2011.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2012.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2013.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2014.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2015.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2016.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2017.clean.txt\n",
      "./data/Scenario_Data/TLE/unzipped/tle2018.clean.txt\n"
     ]
    }
   ],
   "source": [
    "# Clean TLE data, Save as pipe delimitted datasets.\n",
    "tle_files = read_files('./data/Scenario_Data/TLE/unzipped', '.txt')\n",
    "for path in tle_files:\n",
    "    filename = re.sub(r'\\.txt$', '.clean.txt', path)\n",
    "    with open(path, 'r') as file:\n",
    "        with open(filename, 'w', encoding='utf-8') as newfile:\n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    file.close()\n",
    "                    newfile.close()\n",
    "                    print(filename)\n",
    "                    break\n",
    "                \n",
    "                newline = ''\n",
    "                line2 = False\n",
    "                if re.search(r'^2', line):\n",
    "                    newline = '\\r\\n'\n",
    "                    line2 = True\n",
    "   \n",
    "                line = re.sub(r'^(1|2)\\s+', '', line)\n",
    "                line = re.sub(r'(^\\s+|\\s+$)', '', line)\n",
    "                line = re.sub(r'\\\\', '|', line)\n",
    "                line = re.sub(r'\\s+', '|', line)   \n",
    "\n",
    "                # Sometimes Mean Motion and Revolution number are crammed together. Separate.\n",
    "                rx = r'(?<=\\|)\\d{1,2}\\.\\d{13}'\n",
    "                if line2 and re.search(rx, line):\n",
    "                    last_num = re.findall(rx, line)[0]\n",
    "                    mean_motion = last_num[:-5]\n",
    "                    rev_num = last_num[-5:]\n",
    "                    # print(mean_motion, rev_num)\n",
    "                    line = re.sub(rx, mean_motion+'|'+rev_num, line)\n",
    "                    \n",
    "                line = line + newline\n",
    "                newfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatNum</th>\n",
       "      <th>IntnlDesignator</th>\n",
       "      <th>EpochYear</th>\n",
       "      <th>BallisticCoef</th>\n",
       "      <th>SecDerivMeanMotion</th>\n",
       "      <th>DragTerm</th>\n",
       "      <th>EphemerisType</th>\n",
       "      <th>ElemNumCheckSum</th>\n",
       "      <th>SatNum2</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>RightAscension</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ArgPerigree</th>\n",
       "      <th>MeanAnomaly</th>\n",
       "      <th>MeanMotion</th>\n",
       "      <th>RevNumEpochCheckSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26619U</td>\n",
       "      <td>00075A</td>\n",
       "      <td>4118.833903</td>\n",
       "      <td>-.00012193</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>-27028-2</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>26619</td>\n",
       "      <td>98.2038</td>\n",
       "      <td>186.7557</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>94.7873</td>\n",
       "      <td>265.3585</td>\n",
       "      <td>14.570848</td>\n",
       "      <td>182472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18549U</td>\n",
       "      <td>68091DE</td>\n",
       "      <td>4118.596391</td>\n",
       "      <td>.00001801</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>25919-2</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>18549</td>\n",
       "      <td>62.2415</td>\n",
       "      <td>180.1561</td>\n",
       "      <td>704892.0</td>\n",
       "      <td>265.6761</td>\n",
       "      <td>86.2771</td>\n",
       "      <td>12.852684</td>\n",
       "      <td>585614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18727U</td>\n",
       "      <td>87020E</td>\n",
       "      <td>4118.666444</td>\n",
       "      <td>-.00000002</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>4084</td>\n",
       "      <td>18727</td>\n",
       "      <td>73.3600</td>\n",
       "      <td>345.6887</td>\n",
       "      <td>88152.0</td>\n",
       "      <td>270.3999</td>\n",
       "      <td>88.6911</td>\n",
       "      <td>12.642166</td>\n",
       "      <td>754869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18792U</td>\n",
       "      <td>88002E</td>\n",
       "      <td>4118.818402</td>\n",
       "      <td>.00000029</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10000-3</td>\n",
       "      <td>0</td>\n",
       "      <td>6838</td>\n",
       "      <td>18792</td>\n",
       "      <td>82.6017</td>\n",
       "      <td>352.4844</td>\n",
       "      <td>14698.0</td>\n",
       "      <td>138.3284</td>\n",
       "      <td>221.8930</td>\n",
       "      <td>12.655116</td>\n",
       "      <td>752224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19027U</td>\n",
       "      <td>81053MK</td>\n",
       "      <td>4118.823075</td>\n",
       "      <td>.00001280</td>\n",
       "      <td>00000-0</td>\n",
       "      <td>10755-2</td>\n",
       "      <td>0</td>\n",
       "      <td>7395</td>\n",
       "      <td>19027</td>\n",
       "      <td>83.0239</td>\n",
       "      <td>250.9465</td>\n",
       "      <td>84934.0</td>\n",
       "      <td>184.3222</td>\n",
       "      <td>175.7249</td>\n",
       "      <td>13.856401</td>\n",
       "      <td>953590.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SatNum IntnlDesignator    EpochYear BallisticCoef SecDerivMeanMotion  \\\n",
       "0  26619U          00075A  4118.833903    -.00012193            00000-0   \n",
       "1  18549U         68091DE  4118.596391     .00001801            00000-0   \n",
       "2  18727U          87020E  4118.666444    -.00000002            00000-0   \n",
       "3  18792U          88002E  4118.818402     .00000029            00000-0   \n",
       "4  19027U         81053MK  4118.823075     .00001280            00000-0   \n",
       "\n",
       "   DragTerm  EphemerisType  ElemNumCheckSum SatNum2  Inclination  \\\n",
       "0  -27028-2              0              720   26619      98.2038   \n",
       "1   25919-2              0              283   18549      62.2415   \n",
       "2   10000-3              0             4084   18727      73.3600   \n",
       "3   10000-3              0             6838   18792      82.6017   \n",
       "4   10755-2              0             7395   19027      83.0239   \n",
       "\n",
       "   RightAscension  Eccentricity  ArgPerigree  MeanAnomaly  MeanMotion  \\\n",
       "0        186.7557        1921.0      94.7873     265.3585   14.570848   \n",
       "1        180.1561      704892.0     265.6761      86.2771   12.852684   \n",
       "2        345.6887       88152.0     270.3999      88.6911   12.642166   \n",
       "3        352.4844       14698.0     138.3284     221.8930   12.655116   \n",
       "4        250.9465       84934.0     184.3222     175.7249   13.856401   \n",
       "\n",
       "   RevNumEpochCheckSum  \n",
       "0             182472.0  \n",
       "1             585614.0  \n",
       "2             754869.0  \n",
       "3             752224.0  \n",
       "4             953590.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tle_dtypes = {\n",
    "    'SatNum': 'object'\n",
    "    , 'IntnlDesignator': 'object'\n",
    "    , 'EpochYear': np.float64\n",
    "    , 'BallisticCoef': 'object'\n",
    "    , 'SecDerivMeanMotion': 'object'\n",
    "    , 'DragTerm': 'object'\n",
    "    , 'EphemerisType': np.int\n",
    "    , 'ElemNumCheckSum': np.int\n",
    "    , 'SatNum2': 'object'\n",
    "    , 'Inclination': np.float\n",
    "    , 'RightAscension': np.float\n",
    "    , 'Eccentricity': np.float\n",
    "    , 'ArgPerigree': np.float\n",
    "    , 'MeanAnomaly': np.float\n",
    "    , 'MeanMotion': np.float\n",
    "    , 'RevNumEpochCheckSum': np.float\n",
    "}\n",
    "\n",
    "tle_columns = [col for col in tle_dtypes]\n",
    "\n",
    "tle_data = dd.read_csv('./data/Scenario_Data/TLE/unzipped/*.clean.txt'\n",
    "                       , names=tle_columns\n",
    "                       , dtype=tle_dtypes\n",
    "                       , sep='|'\n",
    "                       , encoding='utf-8'\n",
    "                      ) # ISO-8859-1\n",
    "\n",
    "tle_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
